{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data, InMemoryDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "\n",
    "from torch.nn import Linear, Parameter\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool, MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, average_precision_score, confusion_matrix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyOwnDataset(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super().__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0], weights_only=False)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return []\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data.pt']\n",
    "\n",
    "    def process(self):\n",
    "        import os, torch\n",
    "        import pandas as pd\n",
    "        from torch_geometric.data import Data\n",
    "\n",
    "        data_list = []\n",
    "        root_dir = 'edkgdl_all_data'\n",
    "        node_dir = 'Graph_index.txt'\n",
    "        edge_direct_dir = 'Graph_edge_index_direct.txt'\n",
    "        label_dir = 'Graph_label.txt'\n",
    "\n",
    "        n = len([d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))])\n",
    "\n",
    "        b = pd.read_csv(os.path.join(root_dir, label_dir), header=None)\n",
    "\n",
    "        for i in range(n):\n",
    "            file_dir = str(i)\n",
    "            node_path = os.path.join(root_dir, file_dir, node_dir)\n",
    "            edge_path = os.path.join(root_dir, file_dir, edge_direct_dir)\n",
    "\n",
    "            # nodes\n",
    "            y = pd.read_csv(node_path, header=None)\n",
    "            x = torch.tensor(y.values, dtype=torch.float)\n",
    "\n",
    "            # edges\n",
    "            a = pd.read_csv(edge_path, header=None)\n",
    "            edge_index = torch.tensor(a.iloc[:, 0:2].T.values, dtype=torch.long)\n",
    "            edge_attr = torch.tensor(a.iloc[:, 2:].values, dtype=torch.float)\n",
    "\n",
    "            # label\n",
    "            label = torch.tensor(b.iloc[i, 1], dtype=torch.long).reshape(1)\n",
    "\n",
    "            data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=label)\n",
    "            data_list.append(data)\n",
    "\n",
    "        if self.pre_filter is not None:\n",
    "            data_list = [d for d in data_list if self.pre_filter(d)]\n",
    "        if self.pre_transform is not None:\n",
    "            data_list = [self.pre_transform(d) for d in data_list]\n",
    "\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: MyOwnDataset(903):\n",
      "==========================\n",
      "Number of graphs: 903\n",
      "Number of features: 2\n",
      "Number of classes: 2\n",
      "\n",
      "Data(x=[74, 2], edge_index=[2, 657], edge_attr=[657, 2], y=[1])\n",
      "==========================================================\n",
      "Number of nodes: 74\n",
      "Number of edges: 657\n",
      "Average node degree: 8.88\n",
      "Has isolated nodes: True\n",
      "Has self-loops: False\n",
      "Is undirected: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset = MyOwnDataset(\"EDKG-DL_data\")\n",
    "\n",
    "print()\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('==========================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "data = dataset[0] # get the first graph object\n",
    "\n",
    "print()\n",
    "print(data)\n",
    "print('==========================================================')\n",
    "\n",
    "# gather some statistics about the first graph\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Has self-loops: {data.has_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNConvEdge(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels, edge_channels):\n",
    "        super().__init__(aggr='add')  # \"Add\" aggregation (Step 5).\n",
    "        self.lin = Linear(in_channels, out_channels, bias=False)\n",
    "        self.bias = Parameter(torch.empty(2 * out_channels))\n",
    "        self.lin_edge = Linear(edge_channels, out_channels, bias=False)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lin.reset_parameters()\n",
    "        self.bias.data.zero_()\n",
    "        self.lin_edge.reset_parameters()\n",
    "\n",
    "    def forward(self, x, edge_index, ex):\n",
    "        # x has shape [N, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "\n",
    "        # Step 1: Add self-loops to the adjacency matrix.\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "\n",
    "        # Step 2: Linearly transform node feature matrix.\n",
    "        x = self.lin(x)\n",
    "        ex = self.lin_edge(ex)\n",
    "        extended_ex = torch.cat([ex, torch.zeros([x.shape[0],ex.shape[1]], device=ex.device, dtype=ex.dtype)], dim=0)\n",
    "\n",
    "        # Step 3: Compute normalization.\n",
    "        row, col = edge_index\n",
    "        deg = degree(col, x.size(0), dtype=x.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "\n",
    "        # Step 4-5: Start propagating messages.\n",
    "        out = self.propagate(edge_index, x=x, norm=norm, ex=extended_ex)\n",
    "\n",
    "        # Step 6: Apply a final bias vector.\n",
    "        out += self.bias\n",
    "\n",
    "        return out, ex\n",
    "\n",
    "    def message(self, x_j, norm, ex):\n",
    "        # x_j has shape [E, out_channels]\n",
    "\n",
    "        # Step 4: Normalize node features.\n",
    "        return norm.view(-1, 1) * torch.cat([x_j, ex], dim=1)\n",
    "    \n",
    "# model \n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels_1, hidden_channels_2, hidden_channels_3):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GCNConvEdge(dataset.num_node_features, hidden_channels_1, dataset.num_edge_features)\n",
    "        self.conv2 = GCNConvEdge(2 * hidden_channels_1, hidden_channels_2, hidden_channels_1)\n",
    "        self.conv3 = GCNConvEdge(2 * hidden_channels_2, hidden_channels_3, hidden_channels_2)\n",
    "        self.lin = Linear(2 * hidden_channels_3, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch, edge_attr):\n",
    "        # 1. obtain node embeddings and edge embeddings\n",
    "        x, ex = self.conv1(x, edge_index, edge_attr)\n",
    "        x = x.relu()\n",
    "        x, ex = self.conv2(x, edge_index, ex)\n",
    "        x = x.relu()\n",
    "        x, _ = self.conv3(x, edge_index, ex)\n",
    "\n",
    "        # 2. readout layer\n",
    "        x = global_mean_pool(x, batch) # [batch_size, hidden_channels]\n",
    "\n",
    "        # 3. apply a final classifier \n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyOwnDataset(\"EDKG-DL_data\")\n",
    "test_loader = DataLoader(dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 50\n",
    "hidden_size1 = 50\n",
    "hidden_size2 = 20\n",
    "hidden_size3 = 60\n",
    "\n",
    "model = GCN(hidden_channels_1=hidden_size1, hidden_channels_2=hidden_size2, hidden_channels_3=hidden_size3)\n",
    "\n",
    "state_dict = torch.load(\"model_state.pt\", map_location=\"cuda:0\")\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loader):\n",
    "    model.eval()\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        data = data\n",
    "        labels = data.y.squeeze()\n",
    "        out = model(data.x, data.edge_index, data.batch, data.edge_attr)\n",
    "        pred = out.argmax(dim=1)\n",
    "        for i in range(len(labels)):\n",
    "            if pred[i] == 1 and labels[i] == 1: # TruePositive\n",
    "                TP = TP + 1\n",
    "            elif pred[i] == 0 and labels[i] == 0: # TrueNegative\n",
    "                TN = TN + 1\n",
    "            elif pred[i] == 1 and labels[i] == 0: # FalsePositive\n",
    "                FP = FP + 1\n",
    "            else: # FalseNegative\n",
    "                FN = FN + 1\n",
    "        acc = (TP + TN) / (FN + FP + TP + TN)\n",
    "    return TP, TN, FP, FN, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test TruePositives: 77\n",
      "Test TrueNegatives: 806\n",
      "Test FalsePositives: 10\n",
      "Test FalseNegatives: 10\n",
      "Test Accuracy: 0.9778516057585825\n",
      "Test Precision: 0.8850574712643678\n",
      "Test Recall: 0.8850574712643678\n",
      "Test F1-score: 0.8850574712643678\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "TP, TN, FP, FN, acc = test(test_loader)\n",
    "acc = (TP + TN)/(TP + TN + FP + FN)\n",
    "if TP + FP > 0:\n",
    "    pre = TP/ (TP + FP)\n",
    "else:\n",
    "    pre = 0\n",
    "if TP + FN > 0:\n",
    "    recall = TP / (TP + FN)\n",
    "else:\n",
    "    recall = 0\n",
    "if pre + recall > 0:\n",
    "    F1 = 2 * (pre * recall) / (pre + recall)\n",
    "else:\n",
    "    F1 = 0\n",
    "\n",
    "print(f'Test TruePositives: {TP}')\n",
    "print(f'Test TrueNegatives: {TN}')\n",
    "print(f'Test FalsePositives: {FP}')\n",
    "print(f'Test FalseNegatives: {FN}')\n",
    "print(f'Test Accuracy: {acc}')\n",
    "print(f'Test Precision: {pre}')\n",
    "print(f'Test Recall: {recall}')\n",
    "print(f'Test F1-score: {F1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_binary(model, loader, device=None, threshold=0.5, average='binary'):\n",
    "    model.eval()\n",
    "    if device is None:\n",
    "        try:\n",
    "            device = next(model.parameters()).device\n",
    "        except StopIteration:\n",
    "            device = torch.device('cpu')\n",
    "\n",
    "    y_true, y_prob, y_pred = [], [], []\n",
    "\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        out = model(data.x, data.edge_index, data.batch, data.edge_attr)\n",
    "\n",
    "        if out.ndim == 1 or out.shape[1] == 1:\n",
    "            p1 = torch.sigmoid(out.view(-1))\n",
    "            pred = (p1 >= threshold).long()\n",
    "        else:\n",
    "            probs = torch.softmax(out, dim=1)\n",
    "            p1 = probs[:, 1]\n",
    "            pred = probs.argmax(dim=1)\n",
    "\n",
    "        labels = data.y.view(-1).to(out.device).long()\n",
    "\n",
    "        y_true.append(labels.detach().cpu().numpy())\n",
    "        y_prob.append(p1.detach().cpu().numpy())\n",
    "        y_pred.append(pred.detach().cpu().numpy())\n",
    "\n",
    "    y_true = np.concatenate(y_true, axis=0)\n",
    "    y_prob = np.concatenate(y_prob, axis=0)\n",
    "    y_pred = np.concatenate(y_pred, axis=0)\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    pre = precision_score(y_true, y_pred, zero_division=0, average=average)\n",
    "    rec = recall_score(y_true, y_pred, zero_division=0, average=average)\n",
    "    f1  = f1_score(y_true, y_pred, zero_division=0, average=average)\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[0,1])\n",
    "    TN, FP, FN, TP = cm.ravel()\n",
    "\n",
    "    try:\n",
    "        roc_auc = roc_auc_score(y_true, y_prob)\n",
    "    except Exception:\n",
    "        roc_auc = None\n",
    "    try:\n",
    "        pr_auc = average_precision_score(y_true, y_prob)\n",
    "    except Exception:\n",
    "        pr_auc = None\n",
    "\n",
    "    return {\n",
    "        \"TP\": int(TP), \"TN\": int(TN), \"FP\": int(FP), \"FN\": int(FN),\n",
    "        \"accuracy\": float(acc),\n",
    "        \"precision\": float(pre),\n",
    "        \"recall\": float(rec),\n",
    "        \"f1\": float(f1),\n",
    "        \"roc_auc\": None if roc_auc is None else float(roc_auc),\n",
    "        \"pr_auc\": None if pr_auc is None else float(pr_auc),\n",
    "        \"y_true\": y_true,   \n",
    "        \"y_prob\": y_prob,   \n",
    "        \"y_pred\": y_pred  \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 77\n",
      "TN: 806\n",
      "FP: 10\n",
      "FN: 10\n",
      "Accuracy:  0.9779\n",
      "Precision: 0.8851\n",
      "Recall:    0.8851\n",
      "F1-score:  0.8851\n",
      "ROC-AUC:   0.9865055217489295\n",
      "PR-AUC:    0.8643557947189637\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "metrics = evaluate_binary(model, test_loader)\n",
    "\n",
    "print(f\"TP: {metrics['TP']}\")\n",
    "print(f\"TN: {metrics['TN']}\")\n",
    "print(f\"FP: {metrics['FP']}\")\n",
    "print(f\"FN: {metrics['FN']}\")\n",
    "print(f\"Accuracy:  {metrics['accuracy']:.4f}\")\n",
    "print(f\"Precision: {metrics['precision']:.4f}\")\n",
    "print(f\"Recall:    {metrics['recall']:.4f}\")\n",
    "print(f\"F1-score:  {metrics['f1']:.4f}\")\n",
    "print(f\"ROC-AUC:   {metrics['roc_auc'] if metrics['roc_auc'] is not None else 'N/A'}\")\n",
    "print(f\"PR-AUC:    {metrics['pr_auc'] if metrics['pr_auc'] is not None else 'N/A'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
