{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import os\n",
    "import math\n",
    "import json\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.data import Data, InMemoryDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import global_mean_pool, MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, average_precision_score, confusion_matrix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Utils\n",
    "# ---------------------------\n",
    "\n",
    "def get_device(prefer_gpu_index: int = 0) -> torch.device:\n",
    "    if torch.cuda.is_available() and torch.cuda.device_count() > prefer_gpu_index:\n",
    "        return torch.device(f\"cuda:{prefer_gpu_index}\")\n",
    "    return torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Dataset\n",
    "# ---------------------------\n",
    "\n",
    "class EDKGDataset(InMemoryDataset):\n",
    "    \"\"\"\n",
    "    Expected layout:\n",
    "      data_root/\n",
    "        Graph_label.txt        # two columns: compound_id, label\n",
    "        0/\n",
    "          Graph_index.txt\n",
    "          Graph_edge_index_direct.txt\n",
    "        1/\n",
    "          ...\n",
    "    \"\"\"\n",
    "    def __init__(self, data_root: str, cache_root: str, transform=None, pre_transform=None):\n",
    "        self.data_root = Path(data_root)\n",
    "        self._processed_dir = Path(cache_root)\n",
    "        self._processed_dir.mkdir(parents=True, exist_ok=True)\n",
    "        super().__init__(root=str(self._processed_dir), transform=transform, pre_transform=pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0], weights_only=False)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self) -> List[str]:\n",
    "        return []\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self) -> List[str]:\n",
    "        return [\"data.pt\"]\n",
    "\n",
    "    def process(self) -> None:\n",
    "        import pandas as pd\n",
    "\n",
    "        label_path = self.data_root / \"Graph_label.txt\"\n",
    "        if not label_path.exists():\n",
    "            raise FileNotFoundError(f\"Missing label table: {label_path}\")\n",
    "\n",
    "        node_file = \"Graph_index.txt\"\n",
    "        edge_file = \"Graph_edge_index_direct.txt\"\n",
    "\n",
    "        labels_df = pd.read_csv(label_path, header=None)  # [compound_id, label]\n",
    "        compounds = [p for p in self.data_root.iterdir() if p.is_dir() and p.name.isdigit()]\n",
    "        compounds = sorted(compounds, key=lambda p: int(p.name))\n",
    "\n",
    "        data_list: List[Data] = []\n",
    "        for comp_dir in compounds:\n",
    "            idx = int(comp_dir.name)\n",
    "            np_path = comp_dir / node_file\n",
    "            ep_path = comp_dir / edge_file\n",
    "            if not np_path.exists() or not ep_path.exists():\n",
    "                # quietly skip incomplete compound\n",
    "                continue\n",
    "\n",
    "            # node features\n",
    "            ndf = pd.read_csv(np_path, header=None)\n",
    "            x = torch.tensor(ndf.values, dtype=torch.float)\n",
    "\n",
    "            # edges and edge features\n",
    "            edf = pd.read_csv(ep_path, header=None)\n",
    "            edge_index = torch.tensor(edf.iloc[:, 0:2].T.values, dtype=torch.long)\n",
    "            edge_attr = torch.tensor(edf.iloc[:, 2:].values, dtype=torch.float)\n",
    "\n",
    "            # label lookup\n",
    "            row = labels_df[labels_df.iloc[:, 0] == idx]\n",
    "            if row.empty:\n",
    "                # fallback by position if needed\n",
    "                row = labels_df.iloc[[idx]]\n",
    "            y = torch.tensor(int(row.iloc[0, 1]), dtype=torch.long).view(1)\n",
    "\n",
    "            data_list.append(Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y))\n",
    "\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Model\n",
    "# ---------------------------\n",
    "\n",
    "class GCNConvEdge(MessagePassing):\n",
    "    \"\"\"GCN-like layer with linear edge feature mapping and concatenated message.\"\"\"\n",
    "    def __init__(self, in_channels: int, out_channels: int, edge_channels: int):\n",
    "        super().__init__(aggr=\"add\")\n",
    "        self.lin_node = nn.Linear(in_channels, out_channels, bias=False)\n",
    "        self.lin_edge = nn.Linear(edge_channels, out_channels, bias=False)\n",
    "        self.bias = nn.Parameter(torch.zeros(2 * out_channels))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self) -> None:\n",
    "        nn.init.kaiming_uniform_(self.lin_node.weight, a=math.sqrt(5))\n",
    "        nn.init.kaiming_uniform_(self.lin_edge.weight, a=math.sqrt(5))\n",
    "        nn.init.zeros_(self.bias)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, edge_index: torch.Tensor, edge_attr: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        # add self-loops\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "\n",
    "        # map node and edge features\n",
    "        x = self.lin_node(x)\n",
    "        ex = self.lin_edge(edge_attr)\n",
    "\n",
    "        # pad edge embeddings for self-loops (one per node)\n",
    "        ex = torch.cat([ex, torch.zeros((x.size(0), ex.size(1)), device=ex.device, dtype=ex.dtype)], dim=0)\n",
    "\n",
    "        # normalized aggregation coefficients\n",
    "        row, col = edge_index\n",
    "        deg = degree(col, x.size(0), dtype=x.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        deg_inv_sqrt[deg_inv_sqrt == float(\"inf\")] = 0\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "\n",
    "        out = self.propagate(edge_index, x=x, norm=norm, ex=ex)\n",
    "        out = out + self.bias\n",
    "        return out, ex\n",
    "\n",
    "    def message(self, x_j: torch.Tensor, norm: torch.Tensor, ex: torch.Tensor) -> torch.Tensor:\n",
    "        return norm.view(-1, 1) * torch.cat([x_j, ex], dim=1)\n",
    "\n",
    "class EDKGGCN(nn.Module):\n",
    "    def __init__(self, in_node: int, in_edge: int, h1: int, h2: int, h3: int, num_classes: int):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConvEdge(in_node,       h1, in_edge)\n",
    "        self.conv2 = GCNConvEdge(2 * h1,        h2, h1)\n",
    "        self.conv3 = GCNConvEdge(2 * h2,        h3, h2)\n",
    "        self.fc    = nn.Linear(2 * h3, num_classes)\n",
    "\n",
    "    def forward(self, data: Data) -> torch.Tensor:\n",
    "        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "        x, ex = self.conv1(x, edge_index, edge_attr)\n",
    "        x = F.relu(x)\n",
    "        x, ex = self.conv2(x, edge_index, ex)\n",
    "        x = F.relu(x)\n",
    "        x, _  = self.conv3(x, edge_index, ex)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Evaluation\n",
    "# ---------------------------\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_binary(model: nn.Module, loader: DataLoader, device: torch.device,\n",
    "                    threshold: float = 0.5, average: str = \"binary\") -> dict:\n",
    "    model.eval()\n",
    "    y_true, y_prob, y_pred = [], [], []\n",
    "\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        logits = model(batch)\n",
    "\n",
    "        if logits.ndim == 1 or logits.shape[1] == 1:\n",
    "            p1 = torch.sigmoid(logits.view(-1))\n",
    "            pred = (p1 >= threshold).long()\n",
    "        else:\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            p1 = probs[:, 1]\n",
    "            pred = probs.argmax(dim=1)\n",
    "\n",
    "        labels = batch.y.view(-1).long()\n",
    "        y_true.append(labels.detach().cpu().numpy())\n",
    "        y_prob.append(p1.detach().cpu().numpy())\n",
    "        y_pred.append(pred.detach().cpu().numpy())\n",
    "\n",
    "    y_true = np.concatenate(y_true, axis=0)\n",
    "    y_prob = np.concatenate(y_prob, axis=0)\n",
    "    y_pred = np.concatenate(y_pred, axis=0)\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    pre = precision_score(y_true, y_pred, zero_division=0, average=average)\n",
    "    rec = recall_score(y_true, y_pred, zero_division=0, average=average)\n",
    "    f1  = f1_score(y_true, y_pred, zero_division=0, average=average)\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
    "    TN, FP, FN, TP = cm.ravel()\n",
    "\n",
    "    try:\n",
    "        roc_auc = roc_auc_score(y_true, y_prob)\n",
    "    except Exception:\n",
    "        roc_auc = None\n",
    "    try:\n",
    "        pr_auc = average_precision_score(y_true, y_prob)\n",
    "    except Exception:\n",
    "        pr_auc = None\n",
    "\n",
    "    return {\n",
    "        \"TP\": int(TP), \"TN\": int(TN), \"FP\": int(FP), \"FN\": int(FN),\n",
    "        \"accuracy\": float(acc), \"precision\": float(pre),\n",
    "        \"recall\": float(rec), \"f1\": float(f1),\n",
    "        \"roc_auc\": None if roc_auc is None else float(roc_auc),\n",
    "        \"pr_auc\":  None if pr_auc  is None else float(pr_auc),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Main\n",
    "# ---------------------------\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--data_root\", type=str, default=\"edkgdl_all_data\")\n",
    "    parser.add_argument(\"--cache_root\", type=str, default=\"EDKG-DL_cache\")\n",
    "    parser.add_argument(\"--ckpt\", type=str, required=True, help=\"Path to model_state.pt\")\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=64)\n",
    "    parser.add_argument(\"--h1\", type=int, default=50)\n",
    "    parser.add_argument(\"--h2\", type=int, default=20)\n",
    "    parser.add_argument(\"--h3\", type=int, default=60)\n",
    "    parser.add_argument(\"--gpu\", type=int, default=0, help=\"preferred GPU index\")\n",
    "    parser.add_argument(\"--report_path\", type=str, default=None, help=\"Optional path to save JSON report\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    device = get_device(args.gpu)\n",
    "\n",
    "    # Load dataset from cache or build it\n",
    "    dataset = EDKGDataset(data_root=args.data_root, cache_root=args.cache_root)\n",
    "    print(f\"Loaded dataset: graphs={len(dataset)}, node_feats={dataset.num_node_features}, edge_feats={dataset.num_edge_features}, classes={dataset.num_classes}\")\n",
    "\n",
    "    # Build model using dataset dims\n",
    "    model = EDKGGCN(\n",
    "        in_node=dataset.num_node_features,\n",
    "        in_edge=dataset.num_edge_features,\n",
    "        h1=args.h1, h2=args.h2, h3=args.h3,\n",
    "        num_classes=dataset.num_classes\n",
    "    ).to(device)\n",
    "\n",
    "    # Load checkpoint on the chosen device gracefully\n",
    "    ckpt_path = Path(args.ckpt)\n",
    "    if not ckpt_path.exists():\n",
    "        raise FileNotFoundError(f\"Checkpoint not found: {ckpt_path}\")\n",
    "    state = torch.load(str(ckpt_path), map_location=device)\n",
    "    model.load_state_dict(state, strict=True)\n",
    "\n",
    "    # Full-dataset evaluation by default\n",
    "    loader = DataLoader(dataset, batch_size=args.batch_size, shuffle=False)\n",
    "\n",
    "    metrics = evaluate_binary(model, loader, device=device)\n",
    "    print(\"\\n=== Evaluation Results ===\")\n",
    "    print(f\"TP: {metrics['TP']}\")\n",
    "    print(f\"TN: {metrics['TN']}\")\n",
    "    print(f\"FP: {metrics['FP']}\")\n",
    "    print(f\"FN: {metrics['FN']}\")\n",
    "    print(f\"Accuracy:  {metrics['accuracy']:.4f}\")\n",
    "    print(f\"Precision: {metrics['precision']:.4f}\")\n",
    "    print(f\"Recall:    {metrics['recall']:.4f}\")\n",
    "    print(f\"F1-score:  {metrics['f1']:.4f}\")\n",
    "    print(f\"ROC-AUC:   {metrics['roc_auc'] if metrics['roc_auc'] is not None else 'N/A'}\")\n",
    "    print(f\"PR-AUC:    {metrics['pr_auc'] if metrics['pr_auc'] is not None else 'N/A'}\")\n",
    "\n",
    "    if args.report_path:\n",
    "        report = {\n",
    "            \"data_root\": args.data_root,\n",
    "            \"cache_root\": args.cache_root,\n",
    "            \"ckpt\": str(ckpt_path),\n",
    "            \"batch_size\": args.batch_size,\n",
    "            \"hidden_sizes\": [args.h1, args.h2, args.h3],\n",
    "            \"metrics\": metrics\n",
    "        }\n",
    "        with open(args.report_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(report, f, indent=2)\n",
    "        print(f\"\\nSaved JSON report to: {args.report_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
